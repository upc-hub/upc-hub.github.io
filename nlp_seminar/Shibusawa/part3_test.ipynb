{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81e7ae1",
   "metadata": {},
   "source": [
    "# üìù Part 3: Shibusawa Testing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7a6f3",
   "metadata": {},
   "source": [
    "This notebook is provided for you to try out what you've learned in **Part 3: Fine-Tuning LLMs**.\n",
    "\n",
    "You can experiment with loading models, tokenizers, and practicing fine-tuning setups.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Example Cell (You can delete or modify it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92016f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load BERT tokenizer and model (this is just a demonstration)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example: Tokenize sample text\n",
    "inputs = tokenizer(\"Fine-tuning is powerful!\", return_tensors=\"pt\")\n",
    "print(\"Tokenized Inputs:\", inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d519e",
   "metadata": {},
   "source": [
    "## ‚úÖ Continue experimenting below:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
